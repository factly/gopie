import json
import os
from typing import Any, Dict, List, Optional, Tuple

import requests
from dotenv import load_dotenv
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders

from app.core.constants import (
    DATASETS_USED,
    INTERMEDIATE_MESSAGES,
    SQL_QUERIES_GENERATED,
)

from .terminal_formatter import TerminalFormatter

load_dotenv()

REQUEST_TIMEOUT = 120


def setup_model() -> ChatOpenAI:
    api_key = os.getenv("PORTKEY_API_KEY")
    provider = os.getenv("PORTKEY_PROVIDER_NAME")

    return ChatOpenAI(
        api_key="X",  # type: ignore
        base_url=PORTKEY_GATEWAY_URL,
        default_headers=createHeaders(api_key=api_key, provider=provider),
        model="gpt-4o-mini",
    )


def create_evaluation_chain():
    template = """You are a judgemental data analyst assistant.

You will be given:
1. The answer generated by our system in response to a user query
2. Details about the expected result

generated_answer: {generated_answer}
expected_result: {expected_result}

The expected_result may contain:
- dataset_identified: which dataset should be used (only present for multi-dataset cases)
- sql_query_count: number of SQL queries expected
- visualization_needed: whether visualization is required
- visualization_type: what type of visualization is appropriate

Evaluate if the generated answer meets the expected criteria:

RETURN 'true' if:
- The answer correctly identified the expected dataset (if dataset_identified is specified)
- The number of SQL queries used is appropriate (matching sql_query_count if specified)
- Visualization recommendations (if applicable) match the expected result
- The numerical values are within acceptable ranges
- The SQL queries were properly extracted and reported in the response

RETURN 'false' if:
- The answer identified the wrong dataset (when dataset_identified is specified)
- The SQL query count is significantly off
- Visualization was needed but not recommended (or vice versa)
- The answer is factually incorrect
- No SQL queries were detected when they should have been

RETURN 'partial' if:
- The answer is factually correct but there are minor issues with:
  - Dataset identification (when applicable)
  - SQL query count
  - Visualization recommendations
- Or if the answer is partially correct but missing some components

Return the response as JSON object:
{{
    "correct": "true" | "false" | "partial",
    "reasoning": "reasoning for why the answer is incorrect or partial, no reasoning needed for correct answers"
}}"""

    prompt = ChatPromptTemplate.from_template(template)
    return prompt | setup_model() | JsonOutputParser()


def process_tool_calls(tool_calls: List[Dict[str, Any]]) -> Tuple[List[str], List[str], List[str]]:
    tool_messages = []
    generated_sql_queries = []
    selected_datasets = []

    if not tool_calls:
        return tool_messages, generated_sql_queries, selected_datasets

    for tool_call in tool_calls:
        if not tool_call or "function" not in tool_call:
            continue

        function_data = tool_call.get("function", {})
        name = function_data.get("name")

        try:
            args = json.loads(function_data.get("arguments", "{}"))

            if name == SQL_QUERIES_GENERATED:
                _extract_sql_queries(args, generated_sql_queries)

            elif name == DATASETS_USED:
                _extract_datasets(args, selected_datasets)

            elif name == INTERMEDIATE_MESSAGES and args.get("role") == "intermediate":
                content = args.get("content", "")
                category = args.get("category", "")
                tool_messages.append(content)

                if category == DATASETS_USED or (content and "dataset" in content.lower()):
                    _extract_datasets_from_content(args, content, selected_datasets)

                if category == SQL_QUERIES_GENERATED or _contains_sql_keywords(content):
                    _extract_sql_from_content(args, content, generated_sql_queries)

        except json.JSONDecodeError:
            continue

    return tool_messages, generated_sql_queries, selected_datasets


def _extract_sql_queries(args: Dict[str, Any], sql_queries: List[str]) -> None:
    if "query" in args and args.get("query"):
        sql_queries.append(str(args.get("query")))
    elif "queries" in args:
        queries = args.get("queries")
        if isinstance(queries, list):
            sql_queries.extend([str(q) for q in queries if q])
        elif queries:
            sql_queries.append(str(queries))


def _extract_datasets(args: Dict[str, Any], datasets: List[str]) -> None:
    dataset_args = args.get("datasets", [])
    if dataset_args:
        if isinstance(dataset_args, list):
            datasets.extend(dataset_args)
        else:
            datasets.append(str(dataset_args))


def _extract_datasets_from_content(args: Dict[str, Any], content: str, datasets: List[str]) -> None:
    if "datasets" in args:
        _extract_datasets(args, datasets)
    elif ":" in content and any(
        keyword in content.lower() for keyword in ["using dataset", "selected dataset"]
    ):
        datasets_part = content.split(":", 1)[1].strip()
        datasets.append(datasets_part)


def _extract_sql_from_content(args: Dict[str, Any], content: str, sql_queries: List[str]) -> None:
    if "query" in args and args.get("query"):
        sql_queries.append(str(args.get("query")))
    elif "queries" in args:
        _extract_sql_queries(args, sql_queries)
    elif _contains_sql_keywords(content):
        sql_queries.append(content)


def _contains_sql_keywords(content: str) -> bool:
    return any(keyword in content.upper() for keyword in ["SELECT", "FROM", "WHERE"])


def get_user_query(test_case: Dict[str, Any]) -> str:
    if "messages" in test_case:
        for message in test_case["messages"]:
            if message.get("role") == "user":
                return message.get("content", "")
    return test_case.get("query", "")


async def send_chat_request(test_case: Dict[str, Any], url: str) -> Dict[str, Any]:
    query_copy = test_case.copy()
    query_copy.pop("expected_result", None)

    try:
        response = requests.post(
            url,
            json={**query_copy, "chat_id": "", "trace_id": ""},
            headers={"Content-Type": "application/json", "Accept": "text/event-stream"},
            stream=True,
            timeout=REQUEST_TIMEOUT,
        )
        response.raise_for_status()

        final_response = ""
        tool_messages = []
        generated_sql_queries = []
        selected_datasets = []

        for line in response.iter_lines():
            if not line:
                continue

            decoded_line = line.decode("utf-8").strip()
            if not decoded_line.startswith("data:"):
                continue

            if decoded_line == "data: [DONE]":
                break

            try:
                chunk_data = json.loads(decoded_line[len("data: ") :])
                if "choices" in chunk_data and chunk_data["choices"]:
                    delta = chunk_data["choices"][0].get("delta", {})

                    if "content" in delta and delta["content"] is not None:
                        final_response += delta["content"] or ""

                    tool_calls = delta.get("tool_calls")
                    if tool_calls is not None:
                        msgs, queries, datasets = process_tool_calls(tool_calls)
                        tool_messages.extend(msgs)
                        generated_sql_queries.extend(queries)
                        selected_datasets.extend(datasets)
            except json.JSONDecodeError:
                continue

        return {
            "final_response": final_response,
            "tool_messages": tool_messages,
            "generated_sql_queries": generated_sql_queries,
            "selected_datasets": selected_datasets,
        }

    except requests.exceptions.RequestException as e:
        return {"error": f"API request failed: {str(e)}"}


def initialize_test_results(user_query: str, expected_result: Dict[str, Any]) -> Dict[str, Any]:
    return {
        "query": user_query,
        "passed": False,
        "reasoning": "",
        "used_datasets": [],
        "sql_query_count": 0,
        "expected_dataset": "",
        "expected_sql_count": expected_result.get("sql_query_count", "Not specified"),
        "status": "error",
    }


def handle_expected_error(
    results: Dict[str, Any], formatter: Optional[TerminalFormatter]
) -> Dict[str, Any]:
    results.update(
        {
            "evaluation": {"note": "Expected error test case - passed"},
            "status": "success",
            "passed": True,
        }
    )
    if formatter:
        formatter.print_success("Expected error test completed successfully")
    return results


def update_results_with_evaluation(
    results: Dict[str, Any],
    evaluation: Dict[str, Any],
    response: Dict[str, Any],
    expected_result: Dict[str, Any],
    formatter: Optional[TerminalFormatter],
) -> None:
    results.update(
        {
            "reasoning": evaluation.get("reasoning", "No reasoning provided"),
            "used_datasets": response["selected_datasets"],
            "sql_query_count": len(response["generated_sql_queries"]),
            "response": response,
            "evaluation": evaluation,
        }
    )

    if "dataset_identified" in expected_result:
        results["expected_dataset"] = expected_result["dataset_identified"]
    else:
        results["expected_dataset"] = "Not applicable for single dataset case"

    correct = evaluation["correct"]
    if correct == "true":
        results["passed"] = True
        results["status"] = "success"
        if formatter:
            formatter.print_test_result("passed")
    elif correct == "partial":
        results["passed"] = "partial"
        results["status"] = "success"
        if formatter:
            formatter.print_test_result("partial", results["reasoning"])
    else:
        results["status"] = "error"
        if formatter:
            formatter.print_test_result("failed", results["reasoning"])


def get_test_cases(
    single_dataset_cases: List[Dict], multi_dataset_cases: List[Dict], test_type: str = "all"
) -> List[Dict[str, Any]]:
    if test_type == "single":
        return single_dataset_cases
    elif test_type == "multi":
        return multi_dataset_cases
    else:
        return single_dataset_cases + multi_dataset_cases
