{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to path: /home/yuvrajsinh/repos/factly/gopie/chat-server\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Added to path: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.tests.e2e.multi_dataset_cases import COMPLEX_QUERY_CASES\n",
    "\n",
    "TEST_CASES = COMPLEX_QUERY_CASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"PORTKEY_API_KEY\")\n",
    "virtual_key = os.getenv(\"GEMINI_VIRTUAL_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    api_key=\"X\",  # type: ignore\n",
    "    base_url=PORTKEY_GATEWAY_URL,\n",
    "    default_headers=createHeaders(\n",
    "        api_key=api_key,\n",
    "        virtual_key=virtual_key,\n",
    "    ),\n",
    "    model=\"gemini-2.5-flash-preview-04-17\",\n",
    ")\n",
    "\n",
    "llm = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    You are a judgemental data analyst assistant.\n",
    "\n",
    "    You will be given:\n",
    "    1. The answer generated by our system in response to a user query\n",
    "    2. Details about the expected result\n",
    "\n",
    "    generated_answer: {generated_answer}\n",
    "    expected_result: {expected_result}\n",
    "\n",
    "    The expected_result may contain some or all of these details:\n",
    "    - dataset_identified: which dataset should be used (only present for multi-dataset cases)\n",
    "    - sql_query_count: number of SQL queries expected\n",
    "    - visualization_needed: whether visualization is required\n",
    "    - visualization_type: what type of visualization is appropriate\n",
    "\n",
    "    Your task is to evaluate if the generated answer meets the expected criteria:\n",
    "\n",
    "    RETURN 'true' if:\n",
    "    - The answer correctly identified the expected dataset (if dataset_identified is specified)\n",
    "    - The number of SQL queries used is appropriate (matching sql_query_count if specified)\n",
    "    - Visualization recommendations (if applicable) match the expected result\n",
    "    - The numerical values are within acceptable ranges\n",
    "    - The SQL queries were properly extracted and reported in the response\n",
    "\n",
    "    RETURN 'false' if:\n",
    "    - The answer identified the wrong dataset (when dataset_identified is specified)\n",
    "    - The SQL query count is significantly off\n",
    "    - Visualization was needed but not recommended (or vice versa)\n",
    "    - The answer is factually incorrect\n",
    "    - No SQL queries were detected when they should have been\n",
    "\n",
    "    RETURN 'partial' if:\n",
    "    - The answer is factually correct but there are minor issues with:\n",
    "      - Dataset identification (when applicable)\n",
    "      - SQL query count\n",
    "      - Visualization recommendations\n",
    "    - Or if the answer is partially correct but missing some components\n",
    "\n",
    "    RETURN the response as JSON object with the following keys:\n",
    "    {{\n",
    "        \"correct\": \"true\" | \"false\" | \"partial\",\n",
    "        \"reasoning\": \"reasoning for why the answer is incorrect or partial,\n",
    "                      no reasoning needed for correct answers\",\n",
    "    }}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "parser = JsonOutputParser()\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3: Processing query: First find the top 5 companies with highest average net profit in 2022-23, then analyze their CSR spending trends from 2016 to 2023\n",
      "    Final AI Response: I was unable to retrieve the CSR spending trends for the top 5 companies with the highest average net profit in 2022-23.\n",
      "\n",
      "To get the information you're looking for, please try breaking down your request into two steps:\n",
      "\n",
      "1.  First, ask: \"What are the top 5 companies with the highest average net profit in 2022-23?\"\n",
      "2.  Once you have that list, you can then ask for the CSR spending trends for those specific companies, for example: \"What was the CSR spending trend for [Company A], [Company B], [Company C], [Company D], and [Company E] from 2016 to 2023?\"\n",
      "\n",
      "This two-step approach should help in fetching the required details.\n",
      "     used_datasets: ['9975bec1-1133-4b94-8ab2-179bba9ba887', '9975bec1-1133-4b94-8ab2-179bba9ba887']\n",
      "     generated_sql queries: [\"WITH top_companies AS (\\n  SELECT company_name\\n  FROM gp_JrlIdI0yzHQdo\\n  WHERE fiscal_year = '2022-23'\\n  ORDER BY average_net_profit DESC\\n  LIMIT 5\\n)\\nSELECT t.company_name, t.fiscal_year, t.csr_spent\\nFROM gp_JrlIdI0yzHQdo AS t\\nJOIN top_companies AS tc\\n  ON t.company_name = tc.company_name\\nWHERE CAST(SUBSTR(t.fiscal_year, 1, 4) AS INTEGER) BETWEEN 2016 AND 2022\\nORDER BY t.company_name, CAST(SUBSTR(t.fiscal_year, 1, 4) AS INTEGER);\", \"WITH top5 AS (\\n  SELECT company_name\\n  FROM gp_JrlIdI0yzHQdo\\n  WHERE fiscal_year = '2022-23'\\n  ORDER BY average_net_profit DESC\\n  LIMIT 5\\n)\\nSELECT\\n  fiscal_year,\\n  company_name,\\n  csr_spent\\nFROM gp_JrlIdI0yzHQdo\\nWHERE company_name IN (SELECT company_name FROM top5)\\n  AND CAST(SUBSTR(fiscal_year, 1, 4) AS INTEGER) BETWEEN 2016 AND 2022\\nORDER BY company_name, fiscal_year;\", \"WITH top5 AS (\\n  SELECT company_name\\n  FROM gp_JrlIdI0yzHQdo\\n  WHERE fiscal_year = '2022-23'\\n  ORDER BY average_net_profit DESC\\n  LIMIT 5\\n)\\nSELECT\\n  t.fiscal_year,\\n  CAST(SUBSTR(t.fiscal_year, 1, 4) AS INTEGER) AS fiscal_start_year,\\n  t.company_name,\\n  t.csr_spent\\nFROM gp_JrlIdI0yzHQdo t\\nJOIN top5\\n  ON t.company_name = top5.company_name\\nWHERE CAST(SUBSTR(t.fiscal_year, 1, 4) AS INTEGER) BETWEEN 2016 AND 2022\\nORDER BY t.company_name, fiscal_start_year;\"]\n",
      "     tool_messages: ['Checking visualization needs...', 'Analyzing query...', 'Analyzing query...', 'Identifying datasets...', 'Planning query...', 'Error in SQL Execution', 'Planning query...', 'Error in SQL Execution', 'Identifying datasets...', 'Planning query...', 'Error in SQL Execution', 'Sorry, something went wrong. Please try again later']\n",
      "    ❌ Query failed\n",
      "    Reasoning: The system failed to answer the user's query, explicitly stating 'I was unable to retrieve the CSR spending trends'. It also generated 3 SQL queries when only 2 were expected, and all generated SQL queries resulted in 'Error in SQL Execution' as per the tool messages. While the visualization recommendation matches, the core task of answering the question and executing the correct number of successful queries was not met. The dataset identification also appears to be off, showing one repeated dataset ID instead of two distinct ones as expected.\n",
      "    Used dataset: 9975bec1-1133-4b94-8ab2-179bba9ba887, 9975bec1-1133-4b94-8ab2-179bba9ba887\n",
      "    SQL queries: 3\n",
      "    Expected dataset: Not applicable for single dataset case\n",
      "    Expected SQL count: 2\n",
      "\n",
      "2/3: Processing query: Calculate the ratio of CSR spent to prescribed CSR for each company in 2022-23, and identify companies that spent more than prescribed\n",
      "    Final AI Response: For the fiscal year 2022-23, the analysis identified a significant number of companies that spent more than their prescribed Corporate Social Responsibility (CSR) expenditure.\n",
      "\n",
      "While many such companies were found to have overspent on their CSR obligations, the volume of results prevents a full display of individual company names and their specific spent-to-prescribed ratios in this response.\n",
      "\n",
      "If you are interested in particular examples or summary statistics of these companies, please consider refining your query.\n",
      "     used_datasets: ['9975bec1-1133-4b94-8ab2-179bba9ba887']\n",
      "     generated_sql queries: [\"-- Step 1: Compute ratio for all companies in 2022-23\\nSELECT\\n  company_name,\\n  cin,\\n  prescribed_csr_expenditure,\\n  csr_spent,\\n  CASE \\n    WHEN prescribed_csr_expenditure = 0 THEN NULL\\n    ELSE csr_spent / prescribed_csr_expenditure\\n  END AS csr_spent_to_prescribed_ratio\\nFROM gp_JrlIdI0yzHQdo\\nWHERE fiscal_year = '2022-23';\", \"-- Step 2: Identify companies that spent more than prescribed (ratio > 1)\\nWITH ratio_cte AS (\\n  SELECT\\n    company_name,\\n    cin,\\n    prescribed_csr_expenditure,\\n    csr_spent,\\n    CASE \\n      WHEN prescribed_csr_expenditure = 0 THEN NULL\\n      ELSE csr_spent / prescribed_csr_expenditure\\n    END AS ratio\\n  FROM gp_JrlIdI0yzHQdo\\n  WHERE fiscal_year = '2022-23'\\n)\\nSELECT\\n  company_name,\\n  cin,\\n  prescribed_csr_expenditure,\\n  csr_spent,\\n  ratio AS csr_spent_to_prescribed_ratio\\nFROM ratio_cte\\nWHERE ratio > 1\\nORDER BY ratio DESC;\", \"-- Alternatively, a single-step query to get only overspending companies:\\nSELECT\\n  company_name,\\n  cin,\\n  prescribed_csr_expenditure,\\n  csr_spent,\\n  csr_spent / prescribed_csr_expenditure AS csr_spent_to_prescribed_ratio\\nFROM gp_JrlIdI0yzHQdo\\nWHERE fiscal_year = '2022-23'\\n  AND prescribed_csr_expenditure > 0\\n  AND csr_spent > prescribed_csr_expenditure\\nORDER BY csr_spent_to_prescribed_ratio DESC;\", \"SELECT company_name, cin, csr_spent / prescribed_csr_expenditure AS spent_to_prescribed_ratio\\nFROM gp_JrlIdI0yzHQdo\\nWHERE fiscal_year = '2022-23'\\n  AND prescribed_csr_expenditure > 0\\n  AND csr_spent > prescribed_csr_expenditure;\"]\n",
      "     tool_messages: ['Checking visualization needs...', 'Analyzing query...', 'Analyzing query...', 'Analyzing query...', 'Analyzing query...', 'Analyzing query...', 'Identifying datasets...', 'Planning query...', 'SQL Execution completed', 'Sorry, something went wrong. Please try again later']\n",
      "    ❌ Query failed\n",
      "    Reasoning: The `generated_sql_queries` array contains 4 distinct SQL queries, whereas the `expected_result.sql_query_count` is 1. This is a significant mismatch in the number of SQL queries reported/used. While some queries are step-by-step or alternatives, presenting 4 queries when only one is expected constitutes a failure to meet the specified criteria for query count.\n",
      "    Used dataset: 9975bec1-1133-4b94-8ab2-179bba9ba887\n",
      "    SQL queries: 4\n",
      "    Expected dataset: Not applicable for single dataset case\n",
      "    Expected SQL count: 1\n",
      "\n",
      "3/3: Processing query: Analyze the trend of female candidates in SC constituencies from 1971 to 2019, and compare with the total number of SC constituencies in each election year\n",
      "    Final AI Response: Here's an analysis of the trend of female candidates in Scheduled Caste (SC) constituencies compared to the total number of SC constituencies from 1971 to 2019:\n",
      "\n",
      "The number of female candidates contesting elections in SC constituencies has shown a significant upward trend over the period, while the total number of SC constituencies has remained relatively stable, with a slight increase in later years.\n",
      "\n",
      "Here's a breakdown by year:\n",
      "\n",
      "*   **1971:** 14 female candidates contested in 76 SC constituencies.\n",
      "*   **1977:** 10 female candidates contested in 78 SC constituencies.\n",
      "*   **1980:** 17 female candidates contested in 79 SC constituencies.\n",
      "*   **1984:** 13 female candidates contested in 75 SC constituencies.\n",
      "*   **1985:** 2 female candidates contested in 4 SC constituencies.\n",
      "*   **1991:** The number of female candidates saw a notable jump to 48, while there were 76 SC constituencies.\n",
      "*   **1992:** 2 female candidates contested in 3 SC constituencies.\n",
      "*   **1996:** A significant increase was observed with 80 female candidates in 79 SC constituencies.\n",
      "*   **1998:** The number slightly decreased to 49 female candidates, with 79 SC constituencies.\n",
      "*   **1999:** 42 female candidates contested in 79 SC constituencies.\n",
      "*   **2004:** The number of female candidates rose again to 49, with 79 SC constituencies.\n",
      "*   **2009:** Female candidates increased to 91, and the total SC constituencies rose to 84.\n",
      "*   **2014:** The upward trend continued with 107 female candidates in 84 SC constituencies.\n",
      "*   **2019:** The highest number was recorded with 112 female candidates, maintaining 84 SC constituencies.\n",
      "\n",
      "**Key Observations:**\n",
      "\n",
      "*   **Growing Female Representation:** There has been a clear and substantial increase in the number of female candidates contesting from SC constituencies, especially from the 1990s onwards, peaking at 112 candidates in 2019.\n",
      "*   **Stable Constituency Count:** The total number of SC constituencies remained largely consistent, typically fluctuating between 75 and 79, before increasing to 84 from 2009 onwards.\n",
      "*   **Disproportionate Growth:** The growth in female candidates has been far more significant than the modest increase in the number of SC constituencies, suggesting a rising interest and participation of women in these reserved electoral seats over time.\n",
      "     used_datasets: ['db0ee4dc-d75f-4d3d-8672-119a7cf77968', 'e4301feb-a92b-4971-9e8d-ec62ccbe17a6']\n",
      "     generated_sql queries: [\"SELECT fc.year, fc.female_candidates, sc.total_sc_constituencies\\nFROM (\\n  SELECT year, SUM(value) AS female_candidates\\n  FROM gp_WyRPkFKKw47Iv\\n  WHERE LOWER(constituency_type) = LOWER('Scheduled Caste')\\n    AND LOWER(gender) = LOWER('Female')\\n    AND LOWER(category) = LOWER('Contesting Candidates')\\n    AND year BETWEEN 1971 AND 2019\\n  GROUP BY year\\n) AS fc\\nJOIN (\\n  SELECT year, SUM(value) AS total_sc_constituencies\\n  FROM gp_vkUIdXMmWsrtg\\n  WHERE LOWER(constituency_type) = LOWER('Scheduled Caste')\\n    AND year BETWEEN 1971 AND 2019\\n  GROUP BY year\\n) AS sc\\n  ON fc.year = sc.year\\nORDER BY fc.year;\"]\n",
      "     tool_messages: ['Checking visualization needs...', 'Analyzing query...', 'Analyzing query...', 'Identifying datasets...', 'Planning query...', 'SQL Execution completed']\n",
      "    ❌ Query failed\n",
      "    Reasoning: The answer has two main issues. First, the 'generated_sql_queries' section only contains 1 SQL query, whereas the 'expected_result' explicitly specifies `\"sql_query_count\": 2`. While the single query uses subqueries to combine data, it does not meet the specified count of distinct queries. Second, and more critically, the numerical values reported for the total number of SC constituencies in 1985 (4) and 1992 (3) are factually incorrect for Lok Sabha general elections. Lok Sabha SC constituencies consistently range between 75-79 (pre-delimitation) and 84 (post-delimitation) during general elections. These specific values (4 and 3) are outliers and do not represent the general Lok Sabha election context, making the presented data for those years inaccurate and misleading for a trend analysis.\n",
      "    Used dataset: db0ee4dc-d75f-4d3d-8672-119a7cf77968, e4301feb-a92b-4971-9e8d-ec62ccbe17a6\n",
      "    SQL queries: 1\n",
      "    Expected dataset: Not applicable for single dataset case\n",
      "    Expected SQL count: 2\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import traceback\n",
    "\n",
    "from app.core.constants import (\n",
    "    INTERMEDIATE_MESSAGES,\n",
    "    SQL_QUERIES_GENERATED,\n",
    "    DATASETS_USED,\n",
    ")\n",
    "\n",
    "url = \"http://localhost:8001/api/v1/chat/completions\"\n",
    "\n",
    "def process_tool_calls(tool_calls):\n",
    "    tool_messages = []\n",
    "    generated_sql_queries = []\n",
    "    selected_datasets = []\n",
    "\n",
    "    if not tool_calls:\n",
    "        return tool_messages, generated_sql_queries, selected_datasets\n",
    "\n",
    "    for tool_call in tool_calls:\n",
    "        if not tool_call or \"function\" not in tool_call:\n",
    "            continue\n",
    "\n",
    "        function_data = tool_call.get(\"function\", {})\n",
    "        name = function_data.get(\"name\")\n",
    "\n",
    "        try:\n",
    "            args = json.loads(function_data.get(\"arguments\", \"{}\"))\n",
    "\n",
    "            if name == SQL_QUERIES_GENERATED:\n",
    "                if \"query\" in args:\n",
    "                    query = args.get(\"query\")\n",
    "                    generated_sql_queries.append(query)\n",
    "                elif \"queries\" in args:\n",
    "                    queries = args.get(\"queries\")\n",
    "                    if isinstance(queries, list):\n",
    "                        generated_sql_queries.extend(queries)\n",
    "                    else:\n",
    "                        query = str(queries)\n",
    "                        generated_sql_queries.append(query)\n",
    "\n",
    "            elif name == DATASETS_USED:\n",
    "                datasets = args.get(\"datasets\", [])\n",
    "                if datasets:\n",
    "                    if isinstance(datasets, list):\n",
    "                        selected_datasets.extend(datasets)\n",
    "                    else:\n",
    "                        selected_datasets.append(str(datasets))\n",
    "\n",
    "            elif name == INTERMEDIATE_MESSAGES:\n",
    "                content = args.get(\"content\", \"\")\n",
    "                category = args.get(\"category\", \"\")\n",
    "                if args.get(\"role\") == \"intermediate\":\n",
    "                    tool_messages.append(content)\n",
    "\n",
    "                    if category == DATASETS_USED or (content and \"dataset\" in content.lower()):\n",
    "                        if \"datasets\" in args:\n",
    "                            datasets = args.get(\"datasets\")\n",
    "                            if isinstance(datasets, list):\n",
    "                                selected_datasets.extend(datasets)\n",
    "                            else:\n",
    "                                selected_datasets.append(str(datasets))\n",
    "                        elif \":\" in content:\n",
    "                            if \"using dataset\" in content.lower() or \"selected dataset\" in content.lower():\n",
    "                                datasets_part = content.split(\":\", 1)[1].strip()\n",
    "                                selected_datasets.append(datasets_part)\n",
    "\n",
    "                    if category == SQL_QUERIES_GENERATED or (content and ((\"sql\" in content.lower()) or (\"query\" in content.lower()))):\n",
    "                        if \"query\" in args:\n",
    "                            query = args.get(\"query\")\n",
    "                            generated_sql_queries.append(query)\n",
    "                        elif \"queries\" in args:\n",
    "                            queries = args.get(\"queries\")\n",
    "                            if isinstance(queries, list):\n",
    "                                generated_sql_queries.extend(queries)\n",
    "                            else:\n",
    "                                query = str(queries)\n",
    "                                generated_sql_queries.append(query)\n",
    "                        elif \"SELECT\" in content.upper() or \"FROM\" in content.upper() or \"WHERE\" in content.upper():\n",
    "                            generated_sql_queries.append(content)\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "    return tool_messages, generated_sql_queries, selected_datasets\n",
    "\n",
    "async def process_test_cases(test_cases):\n",
    "    for index, query in enumerate(test_cases):\n",
    "        query_copy = query.copy()\n",
    "        expected_result = query_copy.get(\"expected_result\", {})\n",
    "        if \"expected_result\" in query_copy:\n",
    "            del query_copy[\"expected_result\"]\n",
    "\n",
    "        print(f\"{index+1}/{len(test_cases)}: Processing query: {query['messages'][0]['content']}\")\n",
    "\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                url,\n",
    "                json={\n",
    "                    **query_copy,\n",
    "                    \"chat_id\": \"\",\n",
    "                    \"trace_id\": \"\",\n",
    "                },\n",
    "                headers={\n",
    "                    \"Content-Type\": \"application/json\",\n",
    "                    \"Accept\": \"text/event-stream\"\n",
    "                },\n",
    "                stream=True\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "\n",
    "            final_response = \"\"\n",
    "            tool_messages = []\n",
    "            generated_sql_queries = []\n",
    "            selected_datasets = []\n",
    "\n",
    "            for line in response.iter_lines():\n",
    "                if not line:\n",
    "                    continue\n",
    "\n",
    "                decoded_line = line.decode('utf-8').strip()\n",
    "                if not decoded_line.startswith(\"data:\"):\n",
    "                    continue\n",
    "\n",
    "                if decoded_line == \"data: [DONE]\":\n",
    "                    break\n",
    "\n",
    "                try:\n",
    "                    chunk_data = json.loads(decoded_line[len(\"data: \"):])\n",
    "\n",
    "                    if \"choices\" in chunk_data and chunk_data[\"choices\"]:\n",
    "                        delta = chunk_data[\"choices\"][0].get(\"delta\", {})\n",
    "\n",
    "                        if \"content\" in delta and delta[\"content\"] is not None:\n",
    "                            final_response += delta[\"content\"] or \"\"\n",
    "\n",
    "                        tool_calls = delta.get(\"tool_calls\")\n",
    "                        if tool_calls is not None:\n",
    "                            msgs, queries, datasets = process_tool_calls(tool_calls)\n",
    "                            tool_messages.extend(msgs)\n",
    "                            generated_sql_queries.extend(queries)\n",
    "                            selected_datasets.extend(datasets)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "\n",
    "            final_response += f\"\\n     used_datasets: {selected_datasets}\"\n",
    "            final_response += f\"\\n     generated_sql queries: {generated_sql_queries}\"\n",
    "            final_response += f\"\\n     tool_messages: {tool_messages}\"\n",
    "\n",
    "            print(f\"    Final AI Response: {final_response}\")\n",
    "\n",
    "            result = await chain.ainvoke({\n",
    "                \"generated_answer\": final_response,\n",
    "                \"expected_result\": expected_result\n",
    "            })\n",
    "\n",
    "            if result[\"correct\"] == \"true\":\n",
    "                print(\"    ✅ Query passed\")\n",
    "                print(f\"    Used dataset: {', '.join(selected_datasets) if selected_datasets else 'None detected'}\")\n",
    "                print(f\"    SQL queries: {len(generated_sql_queries)}\")\n",
    "            elif result[\"correct\"] == \"false\":\n",
    "                print(\"    ❌ Query failed\")\n",
    "                print(f\"    Reasoning: {result.get('reasoning', 'No reasoning provided')}\")\n",
    "                print(f\"    Used dataset: {', '.join(selected_datasets) if selected_datasets else 'None detected'}\")\n",
    "                print(f\"    SQL queries: {len(generated_sql_queries)}\")\n",
    "            elif result[\"correct\"] == \"partial\":\n",
    "                print(\"    🟡 Query partially correct\")\n",
    "                print(f\"    Reasoning: {result.get('reasoning', 'No reasoning provided')}\")\n",
    "                print(f\"    Used dataset: {', '.join(selected_datasets) if selected_datasets else 'None detected'}\")\n",
    "                print(f\"    SQL queries: {len(generated_sql_queries)}\")\n",
    "\n",
    "            if 'dataset_identified' in expected_result:\n",
    "                print(f\"    Expected dataset: {expected_result['dataset_identified']}\")\n",
    "            else:\n",
    "                print(\"    Expected dataset: Not applicable for single dataset case\")\n",
    "            print(f\"    Expected SQL count: {expected_result.get('sql_query_count', 'Not specified')}\")\n",
    "            if expected_result.get('visualization_needed'):\n",
    "                print(f\"    Expected visualization: {expected_result.get('visualization_type', 'Not specified')}\")\n",
    "\n",
    "            print(\"\")\n",
    "        except Exception as e:\n",
    "            print(f\"API request failed: {str(e)}\")\n",
    "            print(traceback.format_exc())\n",
    "            print(f\"For query: {query['messages'][0]['content']}\")\n",
    "\n",
    "    print(\"\\n--------------------------------\\n\\n\")\n",
    "\n",
    "await process_test_cases(TEST_CASES)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
