"use client";

import * as React from "react";
import { useState, useEffect, forwardRef, useImperativeHandle } from "react";
import { toast } from "sonner";
import Uppy, { UppyFile, Meta } from "@uppy/core";
import AwsS3 from "@uppy/aws-s3";
import {
  validateFileWithDuckDb,
  ValidationResult,
  convertFileWithTypes,
  getSupportedFileExtensions,
  getSupportedMimeTypes,
  detectFileFormat,
  SUPPORTED_FORMATS,
  SupportedFileFormat,
} from "@/lib/validation/validate-file";
import { useDuckDb } from "@/hooks/useDuckDb";
import { Alert, AlertDescription, AlertTitle } from "@/components/ui/alert";
import { AlertCircle, CheckCircle2, AlertTriangle } from "lucide-react";
import { useColumnNameStore } from "@/lib/stores/columnNameStore";
import { useColumnDescriptionStore } from "@/lib/stores/columnDescriptionStore";
import { ColumnNameEditor } from "@/components/dataset/column-name-editor";
import { CustomFileUploader } from "./custom-file-uploader";
import { useUploadStore } from "@/lib/stores/uploadStore";

export interface FileValidationUppyProps {
  projectId: string;
  onUploadSuccess?: (
    file: UppyFile<Meta, Record<string, never>>,
    response: unknown,
    validation: ValidationResult
  ) => void;
  onUploadError?: (error: string) => void;
  onAutoGenerateDescriptions?: (
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    summary: Record<string, any>,
    rows: string[][]
  ) => Promise<void>;
  onUploadTrigger?: (datasetName: string, description: string) => Promise<void>;
  onValidationSuccess?: () => void;
}

export interface FileValidationUppyRef {
  triggerUpload: (datasetName: string, description: string) => Promise<void>;
}

function sanitizeFileName(name: string): string {
  // Remove non-alphanumeric characters except for dots and hyphens
  return name.replace(/[^a-zA-Z0-9.-]/g, "_");
}

function getFileFormatDisplay(format: SupportedFileFormat): string {
  const formatNames = {
    csv: "CSV",
    parquet: "Parquet",
    json: "JSON",
    excel: "Excel",
    duckdb: "DuckDB",
  };
  return formatNames[format] || format.toUpperCase();
}

export const FileValidationUppy = forwardRef<FileValidationUppyRef, FileValidationUppyProps>(function FileValidationUppy({
  projectId,
  onUploadSuccess,
  onAutoGenerateDescriptions,
  onValidationSuccess,
}, ref) {
  // Uppy instance
  const [uppy, setUppy] = useState<Uppy | null>(null);

  // File state - use store for persistence across steps
  const selectedFile = useUploadStore((state) => state.selectedFile);
  const modifiedFile = useUploadStore((state) => state.modifiedFile);
  const detectedFormat = useUploadStore((state) => state.detectedFormat) as SupportedFileFormat | null;
  const setSelectedFile = useUploadStore((state) => state.setSelectedFile);
  const setModifiedFile = useUploadStore((state) => state.setModifiedFile);
  const setDetectedFormat = useUploadStore((state) => state.setDetectedFormat);
  const setOriginalFileName = useUploadStore((state) => state.setOriginalFileName);
  
  // Local state for UI
  const [isUploading, setIsUploading] = useState(false);
  const [uploadProgress, setUploadProgress] = useState(0);

  // Validation state
  const [uploadError, setUploadError] = useState<string | null>(null);
  const { db, isInitialized, isInitializing, error: duckDbError } = useDuckDb();
  
  // Use upload store for shared state
  const validationResult = useUploadStore((state) => state.validationResult);
  const setValidationResult = useUploadStore((state) => state.setValidationResult);
  const setUploadResponse = useUploadStore((state) => state.setUploadResponse);

  // Access column name store hooks
  const columnMappings = useColumnNameStore((state) => state.columnMappings);
  const setColumnMappings = useColumnNameStore(
    (state) => state.setColumnMappings
  );
  const setProjectId = useColumnNameStore((state) => state.setProjectId);
  const resetColumnMappings = useColumnNameStore(
    (state) => state.resetColumnMappings
  );
  const getColumnMappings = useColumnNameStore(
    (state) => state.getColumnMappings
  );
  const getColumnDataTypes = useColumnNameStore(
    (state) => state.getColumnDataTypes
  );
  const hasDataTypeChanges = useColumnNameStore(
    (state) => state.hasDataTypeChanges
  );

  // Access column description store hooks
  const clearColumnDescriptions = useColumnDescriptionStore(
    (state) => state.clearColumnDescriptions
  );

  // Calculate if all column names are valid
  const allColumnsValid = Object.values(columnMappings).every(
    (mapping) => mapping.isValid
  );
  const canUpload =
    (selectedFile !== null || modifiedFile !== null) &&
    allColumnsValid &&
    validationResult?.isValid === true;

  // Expose upload functionality via ref
  useImperativeHandle(ref, () => ({
    triggerUpload: async (datasetName: string, description: string) => {
      console.log('triggerUpload called with:', { datasetName, description });
      console.log('Current state:', { 
        selectedFile: selectedFile?.name, 
        modifiedFile: modifiedFile?.name, 
        canUpload,
        uppyInstance: !!uppy,
        validationResult: !!validationResult
      });
      
      // Make sure we have a file and uppy instance
      if (!uppy) {
        console.error('No uppy instance available');
        throw new Error('Upload not initialized');
      }
      
      if (!selectedFile && !modifiedFile) {
        console.error('No file available for upload');
        throw new Error('No file selected');
      }
      
      await handleUpload(datasetName, description);
    }
  }));

  // Process datatype changes immediately when they happen (only for CSV files)
  const handleDataTypeChange = async () => {
    if (!db || !selectedFile || !isInitialized) {
      toast.error("DuckDB is not initialized or no file selected");
      return;
    }

    // Only support datatype conversion for CSV files
    if (detectedFormat !== "csv") {
      toast.info(
        `Datatype conversion is only supported for CSV files. ${getFileFormatDisplay(
          detectedFormat || "csv"
        )} files will be uploaded as-is.`
      );
      return;
    }

    if (!hasDataTypeChanges()) {
      // If no datatype changes, nothing to do
      return;
    }

    try {
      // Get column mappings and data types
      const mappings = getColumnMappings();
      const dataTypes = getColumnDataTypes();

      // Read the original file as ArrayBuffer
      const buffer = await selectedFile.arrayBuffer();

      // Show processing toast
      toast.loading("Processing datatypes with DuckDB...", {
        id: "process-datatypes",
      });

      // Convert the file with updated datatypes
      const convertedBuffer = await convertFileWithTypes(
        db,
        buffer,
        selectedFile.name,
        mappings,
        dataTypes
      );

      // Create a new File from the converted buffer
      const newFile = new File(
        [convertedBuffer],
        `converted_${selectedFile.name}`,
        { type: selectedFile.type }
      );

      // Update state with the new file
      setModifiedFile(newFile);

      toast.success("File processed with updated datatypes!", {
        id: "process-datatypes",
      });
    } catch (error) {
      const errorMessage =
        error instanceof Error ? error.message : "Unknown error";
      toast.error(`Error processing datatypes: ${errorMessage}`, {
        id: "process-datatypes",
      });
      setUploadError(`Error processing datatypes: ${errorMessage}`);
    }
  };

  // Set project ID in store when component mounts or project ID changes
  useEffect(() => {
    setProjectId(projectId);
  }, [projectId, setProjectId]);
  
  // Sync selected file with validation result when component mounts
  useEffect(() => {
    // If we have a validation result but no selected file, it means we're returning to this step
    if (validationResult && !selectedFile) {
      // We can't reconstruct the File object, but we can show the validation result
      setDetectedFormat(validationResult.format as SupportedFileFormat);
    }
  }, [validationResult, selectedFile, setDetectedFormat]);

  // Initialize Uppy
  useEffect(() => {
    const supportedExtensions = getSupportedFileExtensions();
    const supportedMimeTypes = getSupportedMimeTypes();

    const uppyInstance = new Uppy({
      id: "file-uploader",
      restrictions: {
        maxNumberOfFiles: 1,
        allowedFileTypes: [...supportedExtensions, ...supportedMimeTypes],
        // No maxFileSize - allow files of any size
      },
      autoProceed: false,
      allowMultipleUploads: false,
    });

    uppyInstance.use(AwsS3, {
      endpoint:
        process.env.NEXT_PUBLIC_COMPANION_URL || "http://localhost:3020",
    });

    // Handle upload progress
    uppyInstance.on("upload-progress", (file, progress) => {
      const bytesTotal = progress.bytesTotal || 0;
      if (bytesTotal > 0) {
        setUploadProgress(
          Math.round((progress.bytesUploaded / bytesTotal) * 100)
        );
      }
    });

    // Handle upload start
    uppyInstance.on("upload", () => {
      console.log('Upload event triggered');
      setIsUploading(true);
    });
    
    // Handle file added
    uppyInstance.on("file-added", (file) => {
      console.log('File added to uppy:', file.name, file);
    });

    // Handle upload success
    uppyInstance.on("upload-success", async (file, response) => {
      try {
        // Get column mappings (unused in this context but kept for potential future use)
        // const mappings = getColumnMappings();

        // Log file metadata for debugging
        if (file) {
          console.log("Upload success file metadata:", file.meta);
        }

        // Store the actual upload response for later use
        console.log('Upload success response full structure:', response);
        console.log('Response type:', typeof response);
        console.log('Response keys:', response ? Object.keys(response) : 'null');
        
        // Check various response formats - S3 companion response structure
        if (response && typeof response === 'object') {
          const res = response as Record<string, unknown>;
          console.log('=== DETAILED RESPONSE STRUCTURE ===');
          console.log('Full response:', JSON.stringify(res, null, 2));
          console.log('Response body:', res.body);
          console.log('Response uploadURL:', res.uploadURL);
          console.log('Checking for uploadURL in:', {
            direct: res.uploadURL,
            body: res.body,
            uploadURL: (res.body as Record<string, unknown>)?.uploadURL,
            location: (res.body as Record<string, unknown>)?.location,
            Location: (res.body as Record<string, unknown>)?.Location,
            url: (res.body as Record<string, unknown>)?.url
          });
        }
        
        // Store the response as-is - the wizard will extract the URL
        setUploadResponse(response);
        
        // Call onUploadSuccess callback if provided
        if (onUploadSuccess && file) {
          // Use the current validation result or create a basic one if not available
          const currentValidation = validationResult || {
            isValid: true,
            format: detectedFormat || 'csv',
            columnNames: [],
            columnTypes: [],
            previewData: []
          };
          
          // Call the callback with the file, response, and validation
          console.log('Calling onUploadSuccess with:', { file: file.name, response, validation: currentValidation });
          onUploadSuccess(file, response, currentValidation);
        }

        toast.success("File uploaded to S3 successfully!");

        // Don't reset file states here - keep them for the wizard
        // Only reset upload progress and flags
        setUploadProgress(0);
        setIsUploading(false);
      } catch (error) {
        const errorMessage =
          error instanceof Error ? error.message : "Unknown error";
        setUploadError(`Upload success handler failed: ${errorMessage}`);
        toast.error(`Upload success handler failed: ${errorMessage}`);
      }
    });

    // Handle upload error
    uppyInstance.on("upload-error", (file, error) => {
      setUploadError(error.message);
      toast.error(`Upload failed: ${error.message}`);
      setIsUploading(false);
    });

    setUppy(uppyInstance);

    // Clean up function
    return () => {
      uppyInstance.cancelAll();
    };
  }, [clearColumnDescriptions, getColumnMappings, onUploadSuccess, resetColumnMappings, detectedFormat, setUploadResponse, validationResult]);

  // Handle file selection
  const handleFileSelected = async (file: File) => {
    console.log('handleFileSelected called with:', file.name);
    
    // Detect file format
    const format = detectFileFormat(file.name, file.type);

    if (!format) {
      const supportedFormats = Object.keys(SUPPORTED_FORMATS).join(", ");
      toast.error(
        `Unsupported file format. Supported formats: ${supportedFormats}`
      );
      return;
    }

    // Reset states and store the file
    console.log('Setting selected file in store:', file.name);
    setSelectedFile(file);
    setOriginalFileName(file.name);
    setModifiedFile(null);
    setUploadError(null);
    setValidationResult(null);
    setDetectedFormat(format);
    resetColumnMappings();
    clearColumnDescriptions();

    if (!isInitialized || !db) {
      toast.warning(
        `DuckDB is not initialized for validation. ${getFileFormatDisplay(
          format
        )} file will be uploaded without validation.`
      );
      return;
    }

    try {
      const fileSize = file.size;

      // Skip detailed validation for files > 4GB
      if (fileSize > 4000 * 1000 * 1000) {
        setValidationResult({
          isValid: true,
          format,
          error: `File is larger than 4GB. Will be uploaded and validated on the server.`,
        });
        toast.info(
          `Large ${getFileFormatDisplay(
            format
          )} file detected. Client-side validation skipped, will validate on server.`
        );
        return;
      }

      // Read file as ArrayBuffer for validation
      const buffer = await file.arrayBuffer();

      // Validate file with DuckDB
      const result = await validateFileWithDuckDb(
        db,
        buffer,
        file.name,
        fileSize,
        file.type
      );
      setValidationResult(result);

      console.log('Validation complete. Result:', result);
      console.log('result.isValid:', result.isValid);
      console.log('result.error:', result.error);

      if (!result.isValid) {
        toast.error(
          `${getFileFormatDisplay(format)} validation failed: ${result.error}`
        );
        // Keep the file selected so user can see the error
      } else {
        toast.success(`${getFileFormatDisplay(format)} validation successful!`);

        // Debug the validation result structure
        console.log('Full validation result:', result);
        console.log('result.columnNames:', result.columnNames);
        console.log('result.columnTypes:', result.columnTypes);

        // If validation successful and we have column names, update the column name store
        if (result.columnNames) {
          console.log('Setting column mappings with:', { columnNames: result.columnNames, columnTypes: result.columnTypes });
          setColumnMappings(result.columnNames, result.columnTypes);
          console.log('Column mappings set, calling getColumnMappings to verify:', getColumnMappings());
          
          // Store a reference to the file for the wizard
          const uppyFile = {
            name: file.name,
            size: file.size,
            type: file.type,
            data: file,
            meta: {},
            id: `file-${Date.now()}`
          } as UppyFile<Meta, Record<string, never>>;
          
          // Store the file reference in the upload store
          useUploadStore.getState().setUploadedFile(uppyFile);

          // Auto-generate column descriptions if callback is provided (only for tabular formats)
          if (
            onAutoGenerateDescriptions &&
            result.previewData &&
            ["csv", "parquet", "excel"].includes(format)
          ) {
            // Helper function to safely convert BigInt and other types to serializable values
            const serializeValue = (value: unknown): unknown => {
              if (typeof value === "bigint") {
                return value.toString();
              }
              if (value instanceof Date) {
                return value.toISOString();
              }
              if (Array.isArray(value)) {
                return value.map(serializeValue);
              }
              if (value && typeof value === "object") {
                const serialized: Record<string, unknown> = {};
                for (const [key, val] of Object.entries(value)) {
                  serialized[key] = serializeValue(val);
                }
                return serialized;
              }
              return value;
            };

            // Create summary from validation result using updated column names
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            const summary: Record<string, any> = {};
            result.columnNames.forEach((originalName, index) => {
              // Get the updated name for this column (it will be the same initially)
              const mapping = Object.values(columnMappings).find(
                (m) => m.originalName === originalName
              );
              const updatedName = mapping?.updatedName || originalName;

              summary[updatedName] = {
                type: result.columnTypes?.[index] || "string",
                count: result.previewRowCount || 0,
              };
            });

            // Serialize the preview data to handle BigInt and other non-JSON types
            const serializedRows = serializeValue(
              result.previewData
            ) as string[][];

            // Use preview data as sample rows (non-blocking)
            onAutoGenerateDescriptions(summary, serializedRows).catch(
              (error) => {
                console.error("Auto-generation failed:", error);
                // Don't let auto-generation errors affect the file upload flow
              }
            );
          }
        }
        
        // Call validation success callback if provided
        if (onValidationSuccess) {
          onValidationSuccess();
        }
      }
    } catch (error) {
      const errorMessage =
        error instanceof Error ? error.message : "Unknown error";
      setUploadError(
        `Error processing ${getFileFormatDisplay(format)} file: ${errorMessage}`
      );
      toast.error(
        `Error processing ${getFileFormatDisplay(format)} file: ${errorMessage}`
      );
    }
  };

  // Clear selected file
  const handleClearFile = () => {
    setSelectedFile(null);
    setModifiedFile(null);
    setValidationResult(null);
    setDetectedFormat(null);
    resetColumnMappings();
    setUploadError(null);
    if (uppy) {
      uppy.cancelAll();
    }
  };

  // Handle file upload
  const handleUpload = async (datasetName?: string, description?: string) => {
    console.log('handleUpload called');
    console.log('Upload state check:', {
      uppy: !!uppy,
      selectedFile: selectedFile?.name,
      modifiedFile: modifiedFile?.name,
      canUpload,
      validationResult: !!validationResult
    });
    
    if (!uppy || (!selectedFile && !modifiedFile) || !canUpload) {
      console.error('Upload validation failed:', {
        uppy: !!uppy,
        hasFile: !!(selectedFile || modifiedFile),
        canUpload
      });
      toast.error("Please fix all validation errors before uploading");
      return;
    }

    try {
      // Clear any previous uploads
      uppy.cancelAll();

      // Use the modified file if available, otherwise use the original file
      const fileToUpload = modifiedFile || selectedFile;

      if (!fileToUpload) {
        console.error('No file to upload');
        toast.error("No file available for upload");
        return;
      }

      // Create timestamp for file name
      const timestamp = new Date().getTime();
      const sanitizedName = sanitizeFileName(fileToUpload.name);

      // Format path according to [projectId]/dataset_[time]_filename.ext
      const path = `${projectId}/dataset_${timestamp}_${sanitizedName}`;

      // Use provided dataset name or sanitized filename
      const alias =
        datasetName ||
        sanitizedName.replace(/\.(csv|parquet|json|xlsx|duckdb|db|ddb)$/, "");

      // Add file to Uppy with the custom dataset name stored properly in metadata
      uppy.addFile({
        name: path, // This is the file path for storage
        type: fileToUpload.type,
        data: fileToUpload,
      });

      // Log files before upload
      console.log('Files in uppy before upload:', uppy.getFiles());
      console.log('Uppy state:', uppy.getState());
      
      // Start upload and wait for result
      console.log('Starting upload...');
      console.log('Companion URL:', process.env.NEXT_PUBLIC_COMPANION_URL || "http://localhost:3020");
      const result = await uppy.upload();
      console.log('Upload result:', result);
      
      // Check if upload was successful
      if (result && result.failed && result.failed.length > 0) {
        console.error('Upload failed:', result.failed);
        throw new Error('Upload failed');
      }
      
      // The upload-success event handler will be called automatically
      // and will store the response in the upload store
    } catch (error) {
      const errorMessage =
        error instanceof Error ? error.message : "Unknown error";
      setUploadError(`Upload preparation failed: ${errorMessage}`);
      toast.error(`Upload preparation failed: ${errorMessage}`);
    }
  };

  // Don't show loading here - it's handled at the wizard level
  if (isInitializing) {
    return null;
  }

  if (duckDbError) {
    toast.error(`DuckDB initialization error: ${duckDbError.message}`);
  }

  return (
    <div className="w-full">
      {uploadError && (
        <Alert variant="destructive" className="mb-4">
          <AlertCircle className="h-4 w-4" />
          <AlertTitle>Upload Error</AlertTitle>
          <AlertDescription>{uploadError}</AlertDescription>
        </Alert>
      )}

      {validationResult && (
        <Alert
          variant={validationResult.isValid ? "default" : "destructive"}
          className="mb-4"
        >
          {validationResult.isValid ? (
            validationResult.error &&
            validationResult.error.includes("too large") ? (
              <AlertCircle className="h-4 w-4 text-blue-500" />
            ) : (
              <CheckCircle2 className="h-4 w-4 text-green-500" />
            )
          ) : (
            <AlertCircle className="h-4 w-4" />
          )}
          <AlertTitle>
            {validationResult.isValid
              ? validationResult.error &&
                validationResult.error.includes("too large")
                ? "Large File Detected"
                : `DuckDB ${getFileFormatDisplay(
                    validationResult.format
                  )} Validation Successful`
              : `DuckDB ${getFileFormatDisplay(
                  validationResult.format
                )} Validation Failed`}
          </AlertTitle>
          <AlertDescription>
            {validationResult.error
              ? validationResult.error
              : validationResult.columnNames && (
                  <div className="mt-2">
                    <p>
                      {getFileFormatDisplay(validationResult.format)} file is
                      valid with {validationResult.columnCount} columns:
                    </p>
                    <p className="text-xs mt-1 max-h-20 overflow-y-auto">
                      {validationResult.columnNames.join(", ")}
                    </p>
                    {validationResult.tables &&
                      validationResult.tables.length > 1 && (
                        <p className="text-sm mt-2 text-blue-500">
                          DuckDB file contains {validationResult.tables.length}{" "}
                          tables: {validationResult.tables.join(", ")}
                        </p>
                      )}
                    {modifiedFile && (
                      <p className="text-sm mt-2 text-blue-500 font-medium">
                        File processed with custom datatypes. The column names
                        will be updated during import.
                      </p>
                    )}
                    {hasDataTypeChanges() &&
                      !modifiedFile &&
                      detectedFormat === "csv" && (
                        <p className="text-sm mt-2 text-amber-500">
                          Datatype changes will be applied on next edit
                        </p>
                      )}
                    {detectedFormat &&
                      !["csv"].includes(detectedFormat) &&
                      hasDataTypeChanges() && (
                        <p className="text-sm mt-2 text-gray-500">
                          Datatype conversion is only available for CSV files
                        </p>
                      )}
                  </div>
                )}
          </AlertDescription>
        </Alert>
      )}

      {/* Display rejected rows warning */}
      {validationResult?.isValid &&
        validationResult.rejectedRowCount &&
        validationResult.rejectedRowCount > 0 && (
          <Alert variant="default" className="mb-4 border-amber-200 bg-amber-50 dark:border-amber-800 dark:bg-amber-950">
            <AlertTriangle className="h-4 w-4 text-amber-600 dark:text-amber-400" />
            <AlertTitle className="text-amber-900 dark:text-amber-100">
              Data Type Validation Warnings
            </AlertTitle>
            <AlertDescription className="text-amber-800 dark:text-amber-200">
              <div className="space-y-2">
                <p>
                  {validationResult.rejectedRowCount} row(s) contain data that
                  doesn&apos;t match the expected types and will be excluded from the
                  dataset:
                </p>
                {validationResult.rejectedRows &&
                  validationResult.rejectedRows.slice(0, 5).map((rejection, index) => {
                    let displayMessage = "";
                    
                    if (rejection.actualValue && rejection.actualValue.trim() !== "") {
                      // Show actual value if it exists and is not just whitespace
                      const actualValue = rejection.actualValue.length > 50 ? 
                        `${rejection.actualValue.substring(0, 50)}...` : 
                        rejection.actualValue;
                      displayMessage = `got '${actualValue}'`;
                    } else {
                      // For empty values, just say "is empty" or "is missing"
                      displayMessage = "is empty";
                    }
                    
                    const displayExpectedType = rejection.expectedType === "unknown" ? 
                      "a valid type" : 
                      rejection.expectedType;
                    
                    return (
                      <div key={index} className="text-xs bg-amber-100 dark:bg-amber-900 p-2 rounded border border-amber-200 dark:border-amber-700">
                        <span className="font-medium">Row {rejection.rowNumber}:</span>{" "}
                        Column &apos;{rejection.columnName}&apos; expected{" "}
                        <span className="font-mono text-amber-700 dark:text-amber-300">{displayExpectedType}</span> but {displayMessage}
                        {rejection.errorMessage !== "Data type mismatch" && (
                          <div className="mt-1 text-amber-600 dark:text-amber-400">
                            {rejection.errorMessage}
                          </div>
                        )}
                      </div>
                    );
                  })}
                {validationResult.rejectedRows &&
                  validationResult.rejectedRows.length > 5 && (
                    <p className="text-xs text-amber-700 dark:text-amber-300">
                      ... and {validationResult.rejectedRows.length - 5} more
                      issue(s)
                    </p>
                  )}
                <p className="text-sm font-medium">
                  You can proceed with the upload (rejected rows will be skipped)
                  or fix the data and try again.
                </p>
              </div>
            </AlertDescription>
          </Alert>
        )}

      {/* Display supported file formats */}
      <div className="mb-4 text-sm text-gray-600">
        <p>
          <strong>Supported formats:</strong> CSV, Parquet, JSON, Excel (.xlsx, .xls), DuckDB (.duckdb)
        </p>
        {detectedFormat && (
          <p>
            <strong>Detected format:</strong>{" "}
            {getFileFormatDisplay(detectedFormat)}
            {detectedFormat === "excel" && (
              <span className="text-blue-600 ml-1">
                (will be converted to CSV)
              </span>
            )}
          </p>
        )}
      </div>

      {/* Custom file uploader */}
      <CustomFileUploader
        onFileSelected={handleFileSelected}
        onUpload={handleUpload}
        isUploading={isUploading}
        progress={uploadProgress}
        selectedFile={modifiedFile || selectedFile}
        canUpload={canUpload}
        onClearFile={handleClearFile}
        className="w-full"
        // Show file info when returning to step 1
        fileInfo={validationResult && !selectedFile ? {
          name: `Dataset file (${validationResult.format?.toUpperCase() || 'Unknown'})`,
          size: 0,
          format: validationResult.format
        } : undefined}
      />

      {/* Column name editor with datatype processing callback - only show for tabular formats */}
      {validationResult?.isValid &&
        detectedFormat &&
        ["csv", "parquet", "excel"].includes(detectedFormat) && (
          <ColumnNameEditor onDataTypeChange={handleDataTypeChange} />
        )}
    </div>
  );
});

// Keep the old export for backward compatibility
export { FileValidationUppy as CsvValidationUppy };
